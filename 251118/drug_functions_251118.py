# drug_functions_251118.py

import pandas as pd
import re
import streamlit as st # @st.cache_data ë°ì½”ë ˆì´í„° ë•Œë¬¸ì— í•„ìš”í•©ë‹ˆë‹¤.

# --------------------------------------------------------------------------------------------------
# 1. ë°ì´í„° ë¡œë“œ (Streamlit ìºì‹± ë°ì½”ë ˆì´í„° ìœ ì§€)
# --------------------------------------------------------------------------------------------------
@st.cache_data
def load_data():
    """druglist.csv íŒŒì¼ì„ ë¡œë“œí•˜ê³  ìºì‹œì— ì €ì¥í•©ë‹ˆë‹¤."""
    file_path = r'druglist.csv' 
    try:    
        df = pd.read_csv(file_path, encoding='utf-8', dtype=str) 
        df['ìƒì„¸ì •ë³´'] = df['ìƒì„¸ì •ë³´'].fillna('ìƒí˜¸ì‘ìš© ì •ë³´ ì—†ìŒ')
    
        # ì†Œë¬¸ì ì»¬ëŸ¼ ë¯¸ë¦¬ ìƒì„±
        df['ì œí’ˆëª…A_lower'] = df['ì œí’ˆëª…A'].str.lower()
        df['ì„±ë¶„ëª…A_lower'] = df['ì œí’ˆëª…A'].str.lower() # ì„±ë¶„ëª…Aë¡œ ìˆ˜ì •
        df['ì„±ë¶„ëª…A_lower'] = df['ì„±ë¶„ëª…A'].str.lower() # ì„±ë¶„ëª…Aë¡œ ìˆ˜ì •
        df['ì œí’ˆëª…B_lower'] = df['ì œí’ˆëª…B'].str.lower()
        df['ì„±ë¶„ëª…B_lower'] = df['ì„±ë¶„ëª…B'].str.lower()
        print("âœ… (functions) ì•½ë¬¼ ìƒí˜¸ì‘ìš© ë°ì´í„° ë¡œë“œ ì„±ê³µ!")
        return df
    except FileNotFoundError:
        st.error(f"âŒ '{file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    except Exception as e:
        # Streamlit UI ì—†ì´ ì‹¤í–‰ë  ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ printë„ ì¶”ê°€
        print(f"âŒ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# --------------------------------------------------------------------------------------------------
# 2. ì•½ë¬¼ ê²€ìƒ‰ ë° ìƒí˜¸ì‘ìš© í•¨ìˆ˜ë“¤
# --------------------------------------------------------------------------------------------------

def clean_query(query):
    """ê²€ìƒ‰ì–´ ì •ì œ í•¨ìˆ˜: ê´„í˜¸, íŠ¹ì • ì œí˜• ë‹¨ì–´ë¥¼ ì œê±°í•˜ê³  ì†Œë¬¸ìë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if not query:
        return ""
    # bot_v9.11.pyì˜ clean_query í•¨ìˆ˜ ì‚¬ìš©
    cleaned = re.sub(r'\(.*?\)|\[.*?\]|(ì£¼ì‚¬ì œ|ì •ì œ|ìº¡ìŠ|ì‹œëŸ½)$', '', str(query)).strip().lower() 
    return cleaned

def find_drug_info_optimized(df, query):
    """[V6] (ìƒí˜¸ì‘ìš© ê²€ìƒ‰ìš©) ì¿¼ë¦¬í•œ ì•½ë¬¼ 'ìì²´'ì˜ ì œí’ˆëª…/ì„±ë¶„ëª…ë§Œ íš¨ìœ¨ì ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    # (ë‚´ìš© ìœ ì§€)
    cleaned_query = clean_query(query)
    original_query_lower = str(query).strip().lower()
    search_patterns = {cleaned_query, original_query_lower}
    search_patterns.discard('')
    
    if not search_patterns: return None
    
    valid_patterns = [re.escape(item) for item in search_patterns if item]
    if not valid_patterns: return None
    search_pattern_re = "|".join(valid_patterns)

    drugs_set = set()

    try:
        mask_A = df['ì œí’ˆëª…A_lower'].str.contains(search_pattern_re, na=False) | df['ì„±ë¶„ëª…A_lower'].str.contains(search_pattern_re, na=False)
        results_A = df[mask_A]
        if not results_A.empty:
            drugs_set.update(results_A['ì œí’ˆëª…A_lower'].dropna())
            drugs_set.update(results_A['ì„±ë¶„ëª…A_lower'].dropna())

        mask_B = df['ì œí’ˆëª…B_lower'].str.contains(search_pattern_re, na=False) | df['ì„±ë¶„ëª…B_lower'].str.contains(search_pattern_re, na=False)
        results_B = df[mask_B]
        if not results_B.empty:
            drugs_set.update(results_B['ì œí’ˆëª…B_lower'].dropna())
            drugs_set.update(results_B['ì„±ë¶„ëª…B_lower'].dropna())

    except re.error as e:
        print(f"DEBUG: RegEx error in find_drug_info_optimized - {e} (Pattern: {search_pattern_re})")
        return None 
        
    if not drugs_set: return None 
    
    final_set = {item for item in drugs_set if item and pd.notna(item) and str(item) != 'nan'}
    if not final_set: return None
    return final_set
    
def get_product_list(df, drug_query):
    """ì‚¬ìš©ì ì¿¼ë¦¬ë¡œë¶€í„° ê´€ë ¨ ì œí’ˆëª… ëª©ë¡ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    # (ë‚´ìš© ìœ ì§€: ìˆ«ì/ë‹¨ìœ„ ì œê±° ì „ì²˜ë¦¬ ë¡œì§ ìˆ˜ì •ëœ ë²„ì „)
    cleaned_query = re.sub(r'\(.*?\)|\[.*?\]', '', drug_query, flags=re.IGNORECASE).strip().lower()
    cleaned_query = re.sub(r'\d+[a-zA-Z]+|\d+|ì£¼ì‚¬ì œ|ì •ì œ|ìº¡ìŠ|ì‹œëŸ½|ì‹œëŸ½ì•¡|ì •|ì£¼|ì•¡|ì œ\b|ë°€ë¦¬ê·¸ë¨|ê·¸ë¨|mg|g|ml|l', '', cleaned_query, flags=re.IGNORECASE).strip()
    cleaned_query = cleaned_query.replace('_', '').replace(' ', '').strip()
    
    if not cleaned_query: return set()

    try:
        def preprocess_product_name_for_match(name):
             if pd.isna(name): return ''
             name_str = str(name).lower()
             name_str = re.sub(r'\((.*?)\)|\[.*?\]', '', name_str).strip() 
             name_str = re.sub(r'\d+[a-zA-Z]+|\d+|ì£¼ì‚¬ì œ|ì •ì œ|ìº¡ìŠ|ì‹œëŸ½|ì‹œëŸ½ì•¡|ì •|ì£¼|ì•¡|ì œ\b|ë°€ë¦¬ê·¸ë¨|ê·¸ë¨|mg|g|ml|l', '', name_str, flags=re.IGNORECASE)
             name_str = name_str.replace('_', '').replace(' ', '')
             return name_str.strip()

        # NOTE: ì´ ë¶€ë¶„ì€ app.pyì—ì„œ dfë¥¼ ë¡œë“œí•œ í›„ ì‚¬ìš©ë©ë‹ˆë‹¤.
        product_names_a = df['ì œí’ˆëª…A'].apply(preprocess_product_name_for_match)
        product_names_b = df['ì œí’ˆëª…B'].apply(preprocess_product_name_for_match)
        
        search_condition = (product_names_a == cleaned_query) | (product_names_b == cleaned_query)
        search_results = df[search_condition]

        if search_results.empty: return set()

        products = set(search_results['ì œí’ˆëª…A'].dropna()).union(set(search_results['ì œí’ˆëª…B'].dropna()))
        final_products = {str(p) for p in products if str(p).strip()}
        
        return final_products

    except Exception as e:
        print(f"DEBUG: get_product_listì—ì„œ ì˜¤ë¥˜ ë°œìƒ - {e}")
        return set()

def get_main_component(df, drug_query):
    """ì‚¬ìš©ì ì¿¼ë¦¬ë¡œë¶€í„° ì£¼ì„±ë¶„ì„ ì •í™•íˆ ì¶”ì¶œí•©ë‹ˆë‹¤. (ë‹¨ì¼ ì œí’ˆ ì„ íƒ ì‹œ ì‚¬ìš©)"""
    # (ë‚´ìš© ìœ ì§€: ìˆ«ì/ë‹¨ìœ„ ì œê±° ì „ì²˜ë¦¬ ë¡œì§ ìˆ˜ì •ëœ ë²„ì „)
    cleaned_query = re.sub(r'\(.*?\)|\[.*?\]', '', drug_query, flags=re.IGNORECASE).strip().lower()
    cleaned_query = re.sub(r'\d+[a-zA-Z]+|\d+|ì£¼ì‚¬ì œ|ì •ì œ|ìº¡ìŠ|ì‹œëŸ½|ì‹œëŸ½ì•¡|ì •|ì£¼|ì•¡|ì œ\b|ë°€ë¦¬ê·¸ë¨|ê·¸ë¨|mg|g|ml|l', '', cleaned_query, flags=re.IGNORECASE).strip()
    cleaned_query = cleaned_query.replace('_', '').replace(' ', '')
    
    if not cleaned_query: return set()

    try:
        def preprocess_product_name_for_match(name):
             if pd.isna(name): return ''
             name_str = str(name).lower()
             name_str = re.sub(r'\((.*?)\)|\[.*?\]', '', name_str).strip() 
             name_str = re.sub(r'\d+[a-zA-Z]+|\d+|ì£¼ì‚¬ì œ|ì •ì œ|ìº¡ìŠ|ì‹œëŸ½|ì‹œëŸ½ì•¡|ì •|ì£¼|ì•¡|ì œ\b|ë°€ë¦¬ê·¸ë¨|ê·¸ë¨|mg|g|ml|l', '', name_str, flags=re.IGNORECASE)
             name_str = name_str.replace('_', '').replace(' ', '')
             return name_str.strip()

        product_names_a = df['ì œí’ˆëª…A'].apply(preprocess_product_name_for_match)
        product_names_b = df['ì œí’ˆëª…B'].apply(preprocess_product_name_for_match)
        
        valid_components = set()

        match_A_condition = product_names_a == cleaned_query
        components_A = df[match_A_condition]['ì„±ë¶„ëª…A'].dropna().str.lower().tolist()
        valid_components.update(components_A)

        match_B_condition = product_names_b == cleaned_query
        components_B = df[match_B_condition]['ì„±ë¶„ëª…B'].dropna().str.lower().tolist()
        valid_components.update(components_B)
        
        final_components = {str(c) for c in valid_components if str(c).strip() and str(c) != 'nan'}
        
        return final_components

    except Exception as e:
        print(f"DEBUG: get_main_componentì—ì„œ ì˜¤ë¥˜ ë°œìƒ - {e}")
        return set()

def check_drug_interaction_flexible(df, drug_A_query, drug_B_query):
    """ [V8] ìƒí˜¸ì‘ìš© ê²€ìƒ‰ ë¡œì§ """
    # (ë‚´ìš© ìœ ì§€)
    set_A = find_drug_info_optimized(df, drug_A_query)
    set_B = find_drug_info_optimized(df, drug_B_query)

    if set_A is None:
        return "ì •ë³´ ì—†ìŒ", f"'{drug_A_query}'ì— ëŒ€í•œ ì•½ë¬¼ ì •ë³´ë¥¼ DBì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    if set_B is None:
        return "ì •ë³´ ì—†ìŒ", f"'{drug_B_query}'ì— ëŒ€í•œ ì•½ë¬¼ ì •ë³´ë¥¼ DBì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    valid_patterns_A = [re.escape(item) for item in set_A if item]
    valid_patterns_B = [re.escape(item) for item in set_B if item]

    if not valid_patterns_A or not valid_patterns_B:
          return "ì •ë³´ ì—†ìŒ", f"'{drug_A_query}' ë˜ëŠ” '{drug_B_query}'ì˜ ìœ íš¨í•œ ê²€ìƒ‰ì–´ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    pattern_A = "|".join(valid_patterns_A)
    pattern_B = "|".join(valid_patterns_B)

    # ... (ì¤‘ëµ: ìƒí˜¸ì‘ìš© ê²€ìƒ‰ ë° ìœ„í—˜ë„ íŒë‹¨ ë¡œì§ì€ ê·¸ëŒ€ë¡œ ìœ ì§€) ...
    try:
        cols_A = (df['ì œí’ˆëª…A_lower'].str.contains(pattern_A, na=False, case=False) | df['ì„±ë¶„ëª…A_lower'].str.contains(pattern_A, na=False, case=False))
        cols_B = (df['ì œí’ˆëª…B_lower'].str.contains(pattern_B, na=False, case=False) | df['ì„±ë¶„ëª…B_lower'].str.contains(pattern_B, na=False, case=False))

        cols_C = (df['ì œí’ˆëª…A_lower'].str.contains(pattern_B, na=False, case=False) | df['ì„±ë¶„ëª…A_lower'].str.contains(pattern_B, na=False, case=False))
        cols_D = (df['ì œí’ˆëª…B_lower'].str.contains(pattern_A, na=False, case=False) | df['ì„±ë¶„ëª…B_lower'].str.contains(pattern_A, na=False, case=False))
        
    except re.error as e:
        print(f"DEBUG: RegEx error in check_drug_interaction - {e}")
        return "ì •ë³´ ì—†ìŒ", f"ê²€ìƒ‰ì–´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

    
    interactions = df[(cols_A & cols_B) | (cols_C & cols_D)]

    if interactions.empty:
        return "ì•ˆì „", f"'{drug_A_query}'ì™€ '{drug_B_query}' ê°„ì˜ ìƒí˜¸ì‘ìš© ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."

    
    # ì¿¼ë¦¬ ìì²´ì— ëŒ€í•œ Specific í•„í„°ë§ 
    query_A_lower = clean_query(drug_A_query)
    query_B_lower = clean_query(drug_B_query)

    pattern_A_specific = re.escape(query_A_lower)
    pattern_B_specific = re.escape(query_B_lower)

    cols_A_specific = (interactions['ì œí’ˆëª…A_lower'].str.contains(pattern_A_specific, na=False) | interactions['ì„±ë¶„ëª…A_lower'].str.contains(pattern_A_specific, na=False))
    cols_D_specific = (interactions['ì œí’ˆëª…B_lower'].str.contains(pattern_A_specific, na=False) | interactions['ì„±ë¶„ëª…B_lower'].str.contains(pattern_A_specific, na=False))
    mask_A_specific = cols_A_specific | cols_D_specific
    
    cols_B_specific = (interactions['ì œí’ˆëª…B_lower'].str.contains(pattern_B_specific, na=False) | interactions['ì„±ë¶„ëª…B_lower'].str.contains(pattern_B_specific, na=False))
    cols_C_specific = (interactions['ì œí’ˆëª…A_lower'].str.contains(pattern_B_specific, na=False) | interactions['ì„±ë¶„ëª…A_lower'].str.contains(pattern_B_specific, na=False))
    mask_B_specific = cols_B_specific | cols_C_specific

    specific_interactions = interactions[mask_A_specific & mask_B_specific]
    
    interactions_to_display = interactions 
    
    if not specific_interactions.empty:
        interactions_to_display = specific_interactions
    
    # ìœ„í—˜ë„ íŒë‹¨ ë¡œì§
    interactions_to_display = interactions_to_display.drop_duplicates(subset=['ì œí’ˆëª…A', 'ì„±ë¶„ëª…A', 'ì œí’ˆëª…B', 'ì„±ë¶„ëª…B', 'ìƒì„¸ì •ë³´'])

    dangerous_keywords = [
        "ê¸ˆê¸°", "íˆ¬ì—¬ ê¸ˆì§€", "ë…ì„± ì¦ê°€", "ì¹˜ëª…ì ì¸", "ì‹¬ê°í•œ", "ìœ ì‚° ì‚°ì„±ì¦", 
        "ê³ ì¹¼ë¥¨í˜ˆì¦", "ì‹¬ì‹¤ì„± ë¶€ì •ë§¥", "ìœ„í—˜ì„± ì¦ê°€", "ìœ„í—˜ ì¦ê°€", "ì‹¬ì¥ ë¶€ì •ë§¥", 
        "QTê°„ê²© ì—°ì¥ ìœ„í—˜ ì¦ê°€", "QTì—°ì¥", "ì‹¬ë¶€ì •ë§¥", "ì¤‘ëŒ€í•œ", "ì‹¬ì¥ ëª¨ë‹ˆí„°ë§", 
        "ë³‘ìš©ê¸ˆê¸°", "Torsade de pointes ìœ„í—˜ ì¦ê°€", "ìœ„í—˜ì´ ì¦ê°€í•¨", 
        "ì•½ë¬¼ì´ìƒë°˜ì‘ ë°œìƒ ìœ„í—˜", "ë…ì„±", "í—ˆí˜ˆ", "í˜ˆê´€ê²½ë ¨",
        "íš¡ë¬¸ê·¼ìœµí•´ì™€ ê°™ì€ ì¤‘ì¦ì˜ ê·¼ìœ¡ì´ìƒ ë³´ê³ " 
    ]
    caution_keywords = [
        "ì¹˜ë£Œ íš¨ê³¼ê°€ ì œí•œì ", "ì¤‘ì¦ì˜ ìœ„ì¥ê´€ê³„ ì´ìƒë°˜ì‘", "Alfuzosin í˜ˆì¤‘ë†ë„ ì¦ê°€", 
        "ì–‘ìª½ ì•½ë¬¼ ëª¨ë‘ í˜ˆì¥ë†ë„ ìƒìŠ¹ ê°€ëŠ¥", "Amiodarone í˜ˆì¤‘ë†ë„ ì¦ê°€", 
        "í˜ˆì¤‘ë†ë„ ì¦ê°€", "í˜ˆì¥ ë†ë„ ì¦ê°€", 
        "Finerenone í˜ˆì¤‘ë†ë„ì˜ í˜„ì €í•œ ì¦ê°€ê°€ ì˜ˆìƒë¨"
    ]

    highest_risk_level = -1 
    reasons = []
    
    for index, row in interactions_to_display.iterrows():
        detail_str = str(row['ìƒì„¸ì •ë³´'])
        if detail_str == 'ìƒí˜¸ì‘ìš© ì •ë³´ ì—†ìŒ':
            continue

        prod_A = row['ì œí’ˆëª…A'] if pd.notna(row['ì œí’ˆëª…A']) else row['ì„±ë¶„ëª…A']
        prod_B = row['ì œí’ˆëª…B'] if pd.notna(row['ì œí’ˆëª…B']) else row['ì„±ë¶„ëª…B']
        
        if not pd.notna(prod_A): prod_A = "?"
        if not pd.notna(prod_B): prod_B = "?"
        
        label = f"({prod_A} / {prod_B})"
        
        classified = False
        
        for keyword in dangerous_keywords:
            if keyword in detail_str:
                reasons.append(f"ğŸš¨ **ìœ„í—˜ {label}**: {detail_str}")
                highest_risk_level = max(highest_risk_level, 2)
                classified = True
                break 
        
        if classified:
            continue
            
        for keyword in caution_keywords:
            if keyword in detail_str:
                reasons.append(f"âš ï¸ **ì£¼ì˜ {label}**: {detail_str}")
                highest_risk_level = max(highest_risk_level, 1)
                classified = True
                break
        
        if classified:
            continue
        
        reasons.append(f"â„¹ï¸ **ì •ë³´ {label}**: {detail_str}")
        highest_risk_level = max(highest_risk_level, 0)
    
    if highest_risk_level == 2:
        risk_label = "ìœ„í—˜"
    elif highest_risk_level == 1:
        risk_label = "ì£¼ì˜"
    elif highest_risk_level == 0:
        risk_label = "ì •ë³´ í™•ì¸"
    else:
          return "ì•ˆì „", f"'{drug_A_query}'ì™€ '{drug_B_query}' ê°„ì˜ ìƒí˜¸ì‘ìš© ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    return risk_label, "\n\n".join(reasons)