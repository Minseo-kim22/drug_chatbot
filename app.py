import streamlit as st
import google.generativeai as genai
import time

# --- API í‚¤ ì„¤ì • ---
# .streamlit/secrets.toml íŒŒì¼ì—ì„œ API í‚¤ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])

# --- ëª¨ë¸ ì„¤ì • ---
# ì‚¬ìš©í•  ì œë¯¸ë‚˜ì´ ëª¨ë¸ì„ ì§€ì •í•©ë‹ˆë‹¤.
model = genai.GenerativeModel('gemini-1.5-flash-latest')


st.title("ë‚˜ë§Œì˜ ì•½ë¬¼ ìƒí˜¸ì‘ìš© ê²½ê³  ì±—ë´‡ ğŸ’Š (Gemini Ver.)")

# ì„¸ì…˜ ìƒíƒœì— 'messages'ê°€ ì—†ìœ¼ë©´ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ì•½ë¬¼ ìƒí˜¸ì‘ìš©ì— ëŒ€í•´ ì•Œë ¤ë“œë¦¬ëŠ” AI ì±—ë´‡ì…ë‹ˆë‹¤. ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”."}
    ]

# ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ëª¨ë‘ ë³´ì—¬ì¤ë‹ˆë‹¤.
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ìë¡œë¶€í„° ì…ë ¥ì„ ë°›ìŠµë‹ˆë‹¤.
if prompt := st.chat_input("íƒ€ì´ë ˆë†€ê³¼ ì•„ìŠ¤í”¼ë¦°ì„ í•¨ê»˜ ë³µìš©í•´ë„ ë˜ë‚˜ìš”?"):
    # ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€í•˜ê³  í™”ë©´ì— ë³´ì—¬ì¤ë‹ˆë‹¤.
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # --- Gemini ë‹µë³€ ìƒì„± ---
    with st.spinner('Gemini AIê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤... ğŸ¤”'):
        # AIì—ê²Œ ì—­í• ì„ ë¶€ì—¬í•˜ê³ , ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì „ë‹¬í•©ë‹ˆë‹¤.
        instruction = "ë‹¹ì‹ ì€ ì•½ë¬¼ ìƒí˜¸ì‘ìš© ë° ê±´ê°• ì •ë³´ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´ ì˜í•™ì  ê·¼ê±°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¹œì ˆí•˜ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”:\n"
        response = model.generate_content(instruction + prompt)
        
        # ìµœì¢… ë‹µë³€ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        final_response = response.text

    # AIì˜ ë‹µë³€ì„ í™”ë©´ì— ë³´ì—¬ì¤ë‹ˆë‹¤.
    with st.chat_message("assistant"):
        st.markdown(final_response)
        
    # AIì˜ ë‹µë³€ì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€í•©ë‹ˆë‹¤.
    st.session_state.messages.append({"role": "assistant", "content": final_response})