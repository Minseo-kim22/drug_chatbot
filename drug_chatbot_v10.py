import streamlit as st
import pandas as pd
import re
from fuzzywuzzy import process 

# 1. ë°ì´í„° ë¡œë“œ (í˜ì´ì§€ê°€ ë¡œë“œë  ë•Œ í•œ ë²ˆë§Œ ì‹¤í–‰ë¨)
@st.cache_data
def load_data():
    file_path = r'druglist.csv'
    try:
        # dtype=strì„ ì¶”ê°€í•˜ì—¬ DtypeWarningì„ ë°©ì§€í•©ë‹ˆë‹¤.
        df = pd.read_csv(file_path, encoding='utf-8', dtype=str)
        df['ìƒì„¸ì •ë³´'] = df['ìƒì„¸ì •ë³´'].fillna('ìƒí˜¸ì‘ìš© ì •ë³´ ì—†ìŒ')
        
        # [V6] ì„±ëŠ¥ì„ ìœ„í•´ ëª¨ë“  ê²€ìƒ‰ ëŒ€ìƒ ì»¬ëŸ¼ì„ ì†Œë¬¸ìë¡œ ë¯¸ë¦¬ ë³€í™˜
        df['ì œí’ˆëª…A_lower'] = df['ì œí’ˆëª…A'].str.lower()
        df['ì„±ë¶„ëª…A_lower'] = df['ì„±ë¶„ëª…A'].str.lower()
        df['ì œí’ˆëª…B_lower'] = df['ì œí’ˆëª…B'].str.lower()
        df['ì„±ë¶„ëª…B_lower'] = df['ì„±ë¶„ëª…B'].str.lower()
        print("âœ… (Streamlit) ì•½ë¬¼ ìƒí˜¸ì‘ìš© ë°ì´í„° ë¡œë“œ ì„±ê³µ!")
        return df
    except FileNotFoundError:
        st.error(f"âŒ '{file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. .py íŒŒì¼ê³¼ ê°™ì€ í´ë”ì— ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None
    except UnicodeDecodeError:
        st.error(f"âŒ '{file_path}' íŒŒì¼ ì¸ì½”ë”©ì´ 'utf-8'ì´ ì•„ë‹Œ ê²ƒ ê°™ìŠµë‹ˆë‹¤. (íŒŒì¼ ì¸ì½”ë”©ì„ 'utf-8'ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”)")
        return None
    except Exception as e:
        st.error(f"âŒ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# ë°ì´í„° ë¡œë“œ ì‹¤í–‰
df = load_data()

# [V10] ì˜¤íƒ€ ë³´ì •(fuzzy matching)ì„ ìœ„í•œ ì „ì²´ ì•½ë¬¼/ì„±ë¶„ ë¦¬ìŠ¤íŠ¸ ì¤€ë¹„
all_drug_names_set = set()
if df is not None:
    try:
        # ëª¨ë“  ì œí’ˆëª…ê³¼ ì„±ë¶„ëª…ì„ í•˜ë‚˜ë¡œ í•©ì¹œ í›„, ì¤‘ë³µì„ ì œê±°í•©ë‹ˆë‹¤.
        combined_names = pd.concat([
            df['ì œí’ˆëª…A_lower'], df['ì„±ë¶„ëª…A_lower'],
            df['ì œí’ˆëª…B_lower'], df['ì„±ë¶„ëª…B_lower']
        ]).dropna().unique()
        
        # 'nan' ë¬¸ìì—´ì´ë‚˜ ë„ˆë¬´ ì§§ì€ ë‹¨ì–´(2ê¸€ì ì´í•˜)ëŠ” ì œì™¸
        all_drug_names_set = {str(name) for name in combined_names if pd.notna(name) and len(str(name)) > 2}
        print(f"âœ… (Streamlit) ì˜¤íƒ€ ë³´ì •ìš© ì•½ë¬¼/ì„±ë¶„ DB ì¤€ë¹„ ì™„ë£Œ (ì´ {len(all_drug_names_set)}ê°œ)")
    except Exception as e:
        print(f"âŒ (Streamlit) ì˜¤íƒ€ ë³´ì •ìš© DB ìƒì„± ì‹¤íŒ¨: {e}")


# 2. ì•½ë¬¼ ê²€ìƒ‰ ë° ìƒí˜¸ì‘ìš© í•¨ìˆ˜ë“¤

def clean_query(query):
    """
    ê²€ìƒ‰ì–´ ì •ì œ í•¨ìˆ˜
    ê´„í˜¸, íŠ¹ì • ì œí˜• ë‹¨ì–´ë¥¼ ì œê±°í•˜ê³  ì†Œë¬¸ìë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    if not query:
        return ""
    cleaned = re.sub(r'\(.*?\)|\[.*?\]|(ì£¼ì‚¬ì œ|ì •ì œ|ìº¡ìŠ|ì‹œëŸ½)$', '', str(query)).strip().lower()
    return cleaned

@st.cache_data # [V6] find_drug_info ê²°ê³¼ë„ ìºì‹œí•˜ì—¬ ì†ë„ í–¥ìƒ
def find_drug_info_optimized(df, query):
    """
    [V6] ì¿¼ë¦¬í•œ ì•½ë¬¼ 'ìì²´'ì˜ ì œí’ˆëª…/ì„±ë¶„ëª…ë§Œ íš¨ìœ¨ì ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    (ìƒí˜¸ì‘ìš© 'ìƒëŒ€ë°©'ì„ í¬í•¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.)
    """
    cleaned_query = clean_query(query)
    original_query_lower = str(query).strip().lower()

    # ê²€ìƒ‰ íŒ¨í„´ ìƒì„± (ì •ì œëœ ì¿¼ë¦¬ì™€ ì›ë³¸ ì¿¼ë¦¬ ëª¨ë‘ í¬í•¨)
    search_patterns = {cleaned_query, original_query_lower}
    search_patterns.discard('') # ë¹ˆ ë¬¸ìì—´ ì œê±°
    
    if not search_patterns:
        return None
    
    # | (OR) ì •ê·œì‹ íŒ¨í„´
    # [V7 ìˆ˜ì •] ë¹ˆ íŒ¨í„´ìœ¼ë¡œ ì¸í•œ re.error ë°©ì§€
    valid_patterns = [re.escape(item) for item in search_patterns if item]
    if not valid_patterns:
        return None
    search_pattern_re = "|".join(valid_patterns)


    drugs_set = set()

    try:
        # 1. Aì»¬ëŸ¼ì—ì„œ ê²€ìƒ‰
        mask_A = df['ì œí’ˆëª…A_lower'].str.contains(search_pattern_re, na=False) | \
                 df['ì„±ë¶„ëª…A_lower'].str.contains(search_pattern_re, na=False)
        results_A = df[mask_A]
        
        if not results_A.empty:
            drugs_set.update(results_A['ì œí’ˆëª…A_lower'].dropna())
            drugs_set.update(results_A['ì„±ë¶„ëª…A_lower'].dropna())

        # 2. Bì»¬ëŸ¼ì—ì„œ ê²€ìƒ‰
        mask_B = df['ì œí’ˆëª…B_lower'].str.contains(search_pattern_re, na=False) | \
                 df['ì„±ë¶„ëª…B_lower'].str.contains(search_pattern_re, na=False)
        results_B = df[mask_B]
        
        if not results_B.empty:
            drugs_set.update(results_B['ì œí’ˆëª…B_lower'].dropna())
            drugs_set.update(results_B['ì„±ë¶„ëª…B_lower'].dropna())

    except re.error as e:
        print(f"DEBUG: RegEx error in find_drug_info_optimized - {e} (Pattern: {search_pattern_re})")
        return None # ì˜ëª»ëœ ì •ê·œì‹ ì˜¤ë¥˜ ë°©ì§€
        
    if not drugs_set:
        return None # DBì—ì„œ ì•½ë¬¼ ì •ë³´ë¥¼ ì „í˜€ ì°¾ì„ ìˆ˜ ì—†ìŒ

    # 3. ì›ë³¸ ì¿¼ë¦¬ ì´ë¦„ë„ ìµœì¢… ì…‹ì— ì¶”ê°€
    drugs_set.update(search_patterns)
    
    # 'nan' ë¬¸ìì—´ì´ë‚˜ ë¹ˆ ë¬¸ìì—´ ìµœì¢… ì œê±°
    final_set = {item for item in drugs_set if item and pd.notna(item) and str(item) != 'nan'}

    if not final_set:
        return None

    return final_set
    

def check_drug_interaction_flexible(df, drug_A_query, drug_B_query):
    """ [V8] ì„±ë¶„ ê²€ìƒ‰ í›„, 'ì œí’ˆëª…' ì¼ì¹˜ ê²°ê³¼ë¥¼ ìš°ì„ ì ìœ¼ë¡œ í•„í„°ë§ """
    
    # 1. [V6] ìµœì í™”ëœ í•¨ìˆ˜ í˜¸ì¶œ
    set_A = find_drug_info_optimized(df, drug_A_query)
    set_B = find_drug_info_optimized(df, drug_B_query)

    # 2. ë‘˜ ì¤‘ í•˜ë‚˜ë¼ë„ DBì— ì •ë³´ê°€ ì—†ìœ¼ë©´ ê²€ìƒ‰ ë¶ˆê°€
    if set_A is None:
        return "ì •ë³´ ì—†ìŒ", f"'{drug_A_query}'ì— ëŒ€í•œ ì•½ë¬¼ ì •ë³´ë¥¼ DBì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    if set_B is None:
        return "ì •ë³´ ì—†ìŒ", f"'{drug_B_query}'ì— ëŒ€í•œ ì•½ë¬¼ ì •ë³´ë¥¼ DBì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    # 3. ê° ì§‘í•©ì— ëŒ€í•œ | (OR) ì •ê·œì‹ íŒ¨í„´ì„ ìƒì„±í•©ë‹ˆë‹¤.
    valid_patterns_A = [re.escape(item) for item in set_A if item]
    valid_patterns_B = [re.escape(item) for item in set_B if item]

    if not valid_patterns_A or not valid_patterns_B:
         return "ì •ë³´ ì—†ìŒ", f"'{drug_A_query}' ë˜ëŠ” '{drug_B_query}'ì˜ ìœ íš¨í•œ ê²€ìƒ‰ì–´ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    pattern_A = "|".join(valid_patterns_A)
    pattern_B = "|".join(valid_patterns_B)

    try:
        # 4. [V6] ë¯¸ë¦¬ ì†Œë¬¸ìë¡œ ë³€í™˜í•´ë‘” ì»¬ëŸ¼ì—ì„œ ê²€ìƒ‰
        cols_A = (df['ì œí’ˆëª…A_lower'].str.contains(pattern_A, na=False, case=False) | df['ì„±ë¶„ëª…A_lower'].str.contains(pattern_A, na=False, case=False))
        cols_B = (df['ì œí’ˆëª…B_lower'].str.contains(pattern_B, na=False, case=False) | df['ì„±ë¶„ëª…B_lower'].str.contains(pattern_B, na=False, case=False))

        # 5. B/A ìˆœì„œ
        cols_C = (df['ì œí’ˆëª…A_lower'].str.contains(pattern_B, na=False, case=False) | df['ì„±ë¶„ëª…A_lower'].str.contains(pattern_B, na=False, case=False))
        
        # --- [V14] SyntaxError ë²„ê·¸ ìˆ˜ì • ---
        cols_D = (df['ì œí’ˆëª…B_lower'].str.contains(pattern_A, na=False, case=False) | df['ì„±ë¶„ëª…B_lower'].str.contains(pattern_A, na=False, case=False))
        # --- [V14] ---
        
    except re.error as e:
        print(f"DEBUG: RegEx error in check_drug_interaction - {e}")
        return "ì •ë³´ ì—†ìŒ", f"ê²€ìƒ‰ì–´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

    # 6. (A & B) ë˜ëŠ” (B & A) ì¡°í•©ì— í•´ë‹¹í•˜ëŠ” ëª¨ë“  ìƒí˜¸ì‘ìš©ì„ í•œ ë²ˆì— ì°¾ìŠµë‹ˆë‹¤.
    interactions = df[(cols_A & cols_B) | (cols_C & cols_D)]

    if interactions.empty:
        # ì›ë³¸ ì¿¼ë¦¬ ì´ë¦„ìœ¼ë¡œ ë°˜í™˜
        return "ì•ˆì „", f"'{drug_A_query}'ì™€ '{drug_B_query}' ê°„ì˜ ìƒí˜¸ì‘ìš© ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."

    # --- [V8] 'ì œí’ˆëª…' ìš°ì„  í•„í„°ë§ ë¡œì§ ---
    
    # 1. ì‚¬ìš©ì ì›ë³¸ ì¿¼ë¦¬(ì†Œë¬¸ì)ë¡œ 'íŠ¹ì • ì œí’ˆëª…' ê²€ìƒ‰ íŒ¨í„´ ìƒì„±
    query_A_lower = drug_A_query.lower()
    query_B_lower = drug_B_query.lower()
    
    # ì¿¼ë¦¬ ìì²´ê°€ ì •ê·œì‹ íŠ¹ìˆ˜ë¬¸ìë¥¼ í¬í•¨í•  ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ re.escape ì‚¬ìš©
    pattern_A_specific = re.escape(query_A_lower)
    
    # --- [V13] 'NameError' ë²„ê·¸ ìˆ˜ì • (ìœ ì§€) ---
    pattern_B_specific = re.escape(query_B_lower) 
    # --- [V13] ---

    # 2. 1ì°¨ ê²°ê³¼(interactions) ë‚´ì—ì„œ 'íŠ¹ì • ì œí’ˆëª… A'ê°€ í¬í•¨ëœ í–‰ì„ ì°¾ìŒ
    cols_A_specific = (interactions['ì œí’ˆëª…A_lower'].str.contains(pattern_A_specific, na=False) | interactions['ì„±ë¶„ëª…A_lower'].str.contains(pattern_A_specific, na=False))
    cols_D_specific = (interactions['ì œí’ˆëª…B_lower'].str.contains(pattern_A_specific, na=False) | interactions['ì„±ë¶„ëª…B_lower'].str.contains(pattern_A_specific, na=False))
    mask_A_specific = cols_A_specific | cols_D_specific
    
    # 3. 1ì°¨ ê²°ê³¼(interactions) ë‚´ì—ì„œ 'íŠ¹ì • ì œí’ˆëª… B'ê°€ í¬í•¨ëœ í–‰ì„ ì°¾ìŒ
    cols_B_specific = (interactions['ì œí’ˆëª…B_lower'].str.contains(pattern_B_specific, na=False) | interactions['ì„±ë¶„ëª…B_lower'].str.contains(pattern_B_specific, na=False))
    cols_C_specific = (interactions['ì œí’ˆëª…A_lower'].str.contains(pattern_B_specific, na=False) | interactions['ì„±ë¶„ëª…A_lower'].str.contains(pattern_B_specific, na=False))
    mask_B_specific = cols_B_specific | cols_C_specific

    # 4. Aì™€ B íŠ¹ì • ì œí’ˆëª…ì´ 'ëª¨ë‘' í¬í•¨ëœ í–‰ìœ¼ë¡œ í•„í„°ë§
    specific_interactions = interactions[mask_A_specific & mask_B_specific]
    
    interactions_to_display = interactions # ê¸°ë³¸ê°’ = ëª¨ë“  ì„±ë¶„ ì¼ì¹˜ ê²°ê³¼
    
    if not specific_interactions.empty:
        # 5. 'íŠ¹ì • ì œí’ˆëª…' ì¼ì¹˜ ê²°ê³¼ê°€ ìˆë‹¤ë©´, ê·¸ê²ƒë§Œ ì‚¬ìš©
        interactions_to_display = specific_interactions
    
    # --- [V8] ìœ„í—˜ë„ íŒë‹¨ ë¡œì§ (V7ê³¼ ë™ì¼í•˜ë‚˜, interactions_to_display ì‚¬ìš©) ---
    
    # ì¤‘ë³µ ì œê±°
    interactions_to_display = interactions_to_display.drop_duplicates(subset=['ì œí’ˆëª…A', 'ì„±ë¶„ëª…A', 'ì œí’ˆëª…B', 'ì„±ë¶„ëª…B', 'ìƒì„¸ì •ë³´'])

    dangerous_keywords = [
        "ê¸ˆê¸°", "íˆ¬ì—¬ ê¸ˆì§€", "ë…ì„± ì¦ê°€", "ì¹˜ëª…ì ì¸", "ì‹¬ê°í•œ", "ìœ ì‚° ì‚°ì„±ì¦", 
        "ê³ ì¹¼ë¥¨í˜ˆì¦", "ì‹¬ì‹¤ì„± ë¶€ì •ë§¥", "ìœ„í—˜ì„± ì¦ê°€", "ìœ„í—˜ ì¦ê°€", "ì‹¬ì¥ ë¶€ì •ë§¥", 
        "QTê°„ê²© ì—°ì¥ ìœ„í—˜ ì¦ê°€", "QTì—°ì¥", "ì‹¬ë¶€ì •ë§¥", "ì¤‘ëŒ€í•œ", "ì‹¬ì¥ ëª¨ë‹ˆí„°ë§", 
        "ë³‘ìš©ê¸ˆê¸°", "Torsade de pointes ìœ„í—˜ ì¦ê°€", "ìœ„í—˜ì´ ì¦ê°€í•¨", 
        "ì•½ë¬¼ì´ìƒë°˜ì‘ ë°œìƒ ìœ„í—˜", "ë…ì„±", "í—ˆí˜ˆ", "í˜ˆê´€ê²½ë ¨",
        "íš¡ë¬¸ê·¼ìœµí•´ì™€ ê°™ì€ ì¤‘ì¦ì˜ ê·¼ìœ¡ì´ìƒ ë³´ê³ " 
    ]
    caution_keywords = [
        "ì¹˜ë£Œ íš¨ê³¼ê°€ ì œí•œì ", "ì¤‘ì¦ì˜ ìœ„ì¥ê´€ê³„ ì´ìƒë°˜ì‘", "Alfuzosin í˜ˆì¤‘ë†ë„ ì¦ê°€", 
        "ì–‘ìª½ ì•½ë¬¼ ëª¨ë‘ í˜ˆì¥ë†ë„ ìƒìŠ¹ ê°€ëŠ¥", "Amiodarone í˜ˆì¤‘ë†ë„ ì¦ê°€", 
        "í˜ˆì¤‘ë†ë„ ì¦ê°€", "í˜ˆì¥ ë†ë„ ì¦ê°€", 
        "Finerenone í˜ˆì¤‘ë†ë„ì˜ í˜„ì €í•œ ì¦ê°€ê°€ ì˜ˆìƒë¨"
    ]

    highest_risk_level = -1 # -1=ì•ˆì „, 0=ì •ë³´í™•ì¸, 1=ì£¼ì˜, 2=ìœ„í—˜
    reasons = []
    
    # [V8] í•„í„°ë§ëœ 'interactions_to_display'ë¥¼ ìˆœíšŒí•©ë‹ˆë‹¤.
    for index, row in interactions_to_display.iterrows():
        detail_str = str(row['ìƒì„¸ì •ë³´'])
        if detail_str == 'ìƒí˜¸ì‘ìš© ì •ë³´ ì—†ìŒ':
            continue

        # [V7] ìƒì„¸ì •ë³´ì— ì–´ë–¤ ì œí’ˆëª…ì´ ì—°ê´€ë˜ì—ˆëŠ”ì§€ ì¶”ì¶œ
        prod_A = row['ì œí’ˆëª…A'] if pd.notna(row['ì œí’ˆëª…A']) else row['ì„±ë¶„ëª…A']
        prod_B = row['ì œí’ˆëª…B'] if pd.notna(row['ì œí’ˆëª…B']) else row['ì„±ë¶„ëª…B']
        
        # (nan ë°©ì§€)
        if not pd.notna(prod_A): prod_A = "?"
        if not pd.notna(prod_B): prod_B = "?"
        
        # ì œí’ˆëª…/ì„±ë¶„ëª… ë¼ë²¨ ìƒì„±
        label = f"({prod_A} / {prod_B})"
        
        classified = False
        
        # 1. 'ìœ„í—˜' í‚¤ì›Œë“œ ê²€ì‚¬
        for keyword in dangerous_keywords:
            if keyword in detail_str:
                # [V7] ì œí’ˆëª… ë¼ë²¨ í¬í•¨í•˜ì—¬ ì¶”ê°€
                reasons.append(f"ğŸš¨ **ìœ„í—˜ {label}**: {detail_str}")
                highest_risk_level = max(highest_risk_level, 2)
                classified = True
                break 
        
        if classified:
            continue
            
        # 2. 'ì£¼ì˜' í‚¤ì›Œë“œ ê²€ì‚¬
        for keyword in caution_keywords:
            if keyword in detail_str:
                # [V7] ì œí’ˆëª… ë¼ë²¨ í¬í•¨í•˜ì—¬ ì¶”ê°€
                reasons.append(f"âš ï¸ **ì£¼ì˜ {label}**: {detail_str}")
                highest_risk_level = max(highest_risk_level, 1)
                classified = True
                break
        
        if classified:
            continue
        
        # 3. 'ì •ë³´'
        reasons.append(f"â„¹ï¸ **ì •ë³´ {label}**: {detail_str}")
        highest_risk_level = max(highest_risk_level, 0)
    
    # --- [V7] ìµœì¢… ìœ„í—˜ë„ ë° ê²°ê³¼ ë°˜í™˜ (V6ì™€ ë™ì¼) ---
    if highest_risk_level == 2:
        risk_label = "ìœ„í—˜"
    elif highest_risk_level == 1:
        risk_label = "ì£¼ì˜"
    elif highest_risk_level == 0:
        risk_label = "ì •ë³´ í™•ì¸"
    else:
         return "ì•ˆì „", f"'{drug_A_query}'ì™€ '{drug_B_query}' ê°„ì˜ ìƒí˜¸ì‘ìš© ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    return risk_label, "\n\n".join(reasons)


# [V19] ì˜¤íƒ€ ë³´ì •(fuzzy) ê²€ìƒ‰ í•¨ìˆ˜
def get_fuzzy_match(query, choices_set, score_cutoff=65): # [V19] 75ì ì„ 65ì ìœ¼ë¡œ ìˆ˜ì •
    """ 
    [V15] ì‚¬ìš©ì ì¿¼ë¦¬ì™€ ê°€ì¥ ìœ ì‚¬í•œ ì•½ë¬¼ëª…ì„ ì°¾ìŠµë‹ˆë‹¤. 
    'partial_ratio'ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§§ì€ ì¿¼ë¦¬ê°€ ê¸´ DB í•­ëª©ì˜ 'ì¼ë¶€'ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
    
    [V19] ì»·ì˜¤í”„ë¥¼ 65ì ìœ¼ë¡œ ë‚®ì¶° 'ë¶€ë¥´íœ'(67ì ) ì¼€ì´ìŠ¤ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
    """
    if not query or not choices_set:
        return None
        
    try:
        # [V15 ìˆ˜ì •] 'partial_ratio'ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        best_match = process.extractOne(query.lower(), choices_set, scorer=fuzz.partial_ratio) 
        
        if best_match and best_match[1] >= score_cutoff: # [V19] ê¸°ì¤€ì ì´ 65ì ìœ¼ë¡œ ë‚®ì•„ì§
            return best_match[0] # ìœ ì‚¬ë„ê°€ 65ì  ì´ìƒì¸ ì•½ë¬¼ëª… ë°˜í™˜
            
    except Exception as e:
        print(f"DEBUG: Fuzzy matching error - {e}")
        
    return None # ì ì ˆí•œ ë§¤ì¹­ì„ ì°¾ì§€ ëª»í•¨


# 3. Streamlit ì›¹ì‚¬ì´íŠ¸ UI ì½”ë“œ
# [V14] V11 (ê¸°ë³¸ UI) + V13/V14 (ë²„ê·¸ ìˆ˜ì •)
st.title("ğŸ’Š ì•½ë¬¼ ìƒí˜¸ì‘ìš© ì±—ë´‡ (V17)")
st.caption("ìº¡ìŠ¤í†¤ í”„ë¡œì íŠ¸: ì•½ë¬¼ ìƒí˜¸ì‘ìš© ì •ë³´ ê²€ìƒ‰ ì±—ë´‡ (ì„±ë¶„ ê²€ìƒ‰ ìˆ˜ì •)")

if "messages" not in st.session_state:
    st.session_state.messages = []

if not st.session_state.messages:
    st.session_state.messages.append(
        {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ì•½ë¬¼ ìƒí˜¸ì‘ìš© ì±—ë´‡ì…ë‹ˆë‹¤.\n\n[ì§ˆë¬¸ ì˜ˆì‹œ]\n1. íƒ€ì´ë ˆë†€ ì„±ë¶„ì´ ë­ì•¼?\n2. íƒ€ì´ë ˆë†€ê³¼ ì•„ìŠ¤í”¼ë¦°ì„ ê°™ì´ ë³µìš©í•´ë„ ë¼?"}
    )

# [V11] ì±„íŒ… ê¸°ë¡ í‘œì‹œ (ê¸°ë³¸ UI)
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if df is None:
    st.error("ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ë¡œ ì±—ë´‡ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
else:
    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”... (ì˜ˆ: íƒ€ì´ë ˆë†€(500mg)ê³¼ ì•„ìŠ¤í”¼ë¦°)"):
        
        # [V11] ì‚¬ìš©ì ì§ˆë¬¸ì„ ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # [V11] ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ (ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ìƒì„±)
        reply_message = ""
        
        # --- [V17] 'ì„±ë¶„' ì§ˆë¬¸ ì •ê·œì‹ ìˆ˜ì • ---
        match_component = re.match(r'(.+?)\s*(?:ì£¼)?ì„±ë¶„[ì´]?[ ]?(?:ë­ì•¼|ì•Œë ¤ì¤˜)?\??$', prompt.strip())
        
        # --- [V11] 1. ì„±ë¶„ ì§ˆë¬¸ ì²˜ë¦¬ (V10 ì˜¤íƒ€ë³´ì • ë¡œì§ í¬í•¨) ---
        if match_component:
            drug_name = match_component.group(1).strip()
            
            if drug_name:
                with st.spinner(f"ğŸ”„ '{drug_name}' ì„±ë¶„ ê²€ìƒ‰ ì¤‘..."):
                    drugs_set = find_drug_info_optimized(df, drug_name)
                
                if drugs_set is not None:
                    components = {str(d) for d in drugs_set if pd.notna(d) and str(d).strip() and len(str(d)) > 1 and str(d) != 'nan'}
                    if components:
                        reply_message = f"**âœ… '{drug_name}'ì˜ ê´€ë ¨ ì„±ë¶„/ì œí’ˆëª…**\n\n* {', '.join(components)}"
                    else:
                        reply_message = f"â„¹ï¸ '{drug_name}'ì„(ë¥¼) ì°¾ì•˜ìœ¼ë‚˜, ì—°ê´€ëœ ì„±ë¶„ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                else:
                    # [V10] ì˜¤íƒ€ ë³´ì • ë¡œì§
                    suggestion = get_fuzzy_match(drug_name, all_drug_names_set)
                    if suggestion:
                        reply_message = f"â„¹ï¸ '{drug_name}'(ì„)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\ní˜¹ì‹œ **'{suggestion}'**(ìœ¼)ë¡œ ê²€ìƒ‰í•˜ì‹œê² ì–´ìš”?"
                    else:
                        reply_message = f"âŒ '{drug_name}'ì— ëŒ€í•œ ì •ë³´ë¥¼ ìƒí˜¸ì‘ìš© ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            else:
                reply_message = "âŒ ì–´ë–¤ ì•½ë¬¼ì˜ ì„±ë¶„ì„ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”? ì•½ë¬¼ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
        
        # --- [V11] 2. ìƒí˜¸ì‘ìš© ì§ˆë¬¸ ì²˜ë¦¬ (V10 ì˜¤íƒ€ë³´ì • ë¡œì§ í¬í•¨) ---
        else:
            # (V11ê³¼ ë™ì¼í•œ ì •ê·œì‹)
            match_interaction = re.match(r'(.+?)\s*(?:ì´ë‘|ë‘|ê³¼|ì™€|í•˜ê³ )\s+(.+?)(?:ë¥¼|ì„)?\s+(?:ê°™ì´|í•¨ê»˜)\s+(?:ë³µìš©í•´ë„|ë¨¹ì–´ë„)\s+(?:ë¼|ë˜ë‚˜|ë ê¹Œ|ë˜ë‚˜ìš”)\??', prompt.strip())
            if not match_interaction:
                 match_interaction_sep = re.match(r'^\s*(.+?)\s*(?:ì´ë‘|ë‘|ê³¼|ì™€|í•˜ê³ )\s+(.+?)\s*$', prompt.strip())
                 if match_interaction_sep:
                       match_interaction = match_interaction_sep
            if not match_interaction:
                 match_interaction_simple = re.match(r'^\s*([^\s].*?)\s+([^\s].*?)\s*$', prompt.strip())
                 if match_interaction_simple:
                       match_interaction = match_interaction_simple

            if match_interaction:
                drug_A_query = match_interaction.group(1).strip()
                drug_B_query = match_interaction.group(2).strip()
                
                if drug_A_query and drug_B_query:
                    # [V14] ëª¨ë“  ë²„ê·¸ê°€ ìˆ˜ì •ëœ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
                    with st.spinner(f"ğŸ”„ '{drug_A_query}'ì™€ '{drug_B_query}' ìƒí˜¸ì‘ìš© ê²€ìƒ‰ ì¤‘..."):
                        risk, explanation = check_drug_interaction_flexible(df, drug_A_query, drug_B_query)
                    
                    if risk == "ì •ë³´ ì—†ìŒ":
                        # [V10] ì˜¤íƒ€ ë³´ì • ë¡œì§
                        suggestion_A = None
                        suggestion_B = None
                        if f"'{drug_A_query}'" in explanation:
                            suggestion_A = get_fuzzy_match(drug_A_query, all_drug_names_set)
                        if f"'{drug_B_query}'" in explanation:
                            suggestion_B = get_fuzzy_match(drug_B_query, all_drug_names_set)
                        
                        suggestion_text = ""
                        if suggestion_A:
                            suggestion_text += f"\n\n* '{drug_A_query}'(ì€)ëŠ” í˜¹ì‹œ **'{suggestion_A}'**(ì´)ì¸ê°€ìš”?"
                        if suggestion_B:
                            suggestion_text += f"\n\n* '{drug_B_query}'(ì€)ëŠ” í˜¹ì‹œ **'{suggestion_B}'**(ì´)ì¸ê°€ìš”?"

                        if suggestion_text:
                            reply_message = f"**âš ï¸ ì•½ë¬¼ ì •ë³´ ì—†ìŒ (ì˜¤íƒ€ ì œì•ˆ)**\n\n{explanation}{suggestion_text}"
                        else:
                            reply_message = f"**âŒ ì•½ë¬¼ ì •ë³´ ì—†ìŒ**\n\n{explanation}"
                            
                    elif risk == "ì•ˆì „":
                        reply_message = f"**âœ… ì•½ë¬¼ ìƒí˜¸ì‘ìš© ìœ„í—˜ë„: ì•ˆì „**\n\n**ğŸ’¡ ìƒì„¸ ì •ë³´:**\n\n'{drug_A_query}'ì™€ '{drug_B_query}' ê°„ì˜ ìƒí˜¸ì‘ìš© ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
                    
                    else: # ìœ„í—˜, ì£¼ì˜, ì •ë³´ í™•ì¸
                        details = f"**ğŸ’¡ ìƒì„¸ ì •ë³´:**\n\n{explanation}"
                        if risk == "ìœ„í—˜":
                            reply_message = f"**ğŸš¨ ì•½ë¬¼ ìƒí˜¸ì‘ìš© ìœ„í—˜ë„: {risk}**\n\n{details}"
                        elif risk == "ì£¼ì˜":
                            reply_message = f"**âš ï¸ ì•½ë¬¼ ìƒí˜¸ì‘ìš© ìœ„í—˜ë„: {risk}**\n\n{details}"
                        else: # "ì •ë³´ í™•ì¸"
                            reply_message = f"**â„¹ï¸ ì•½ë¬¼ ìƒí˜¸ì‘ìš© ìœ„í—˜ë„: {risk}**\n\n{details}"
                else:
                    reply_message = "âŒ ë‘ ì•½ë¬¼ ì´ë¦„ì„ ì •í™•íˆ ì…ë ¥í•´ì£¼ì„¸ìš”. ì˜ˆ: (A)ì•½ë¬¼ê³¼ (B)ì•½ë¬¼ì„ ê°™ì´ ë³µìš©í•´ë„ ë¼?"
            
            # --- [V11] 3. ì´í•´í•  ìˆ˜ ì—†ëŠ” ì§ˆë¬¸ ---
            else:
                reply_message = "ğŸ¤” ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ í˜•ì‹ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n\n**[ì§ˆë¬¸ ì˜ˆì‹œ]**\n* íƒ€ì´ë ˆë†€ê³¼ ì•„ìŠ¤í”¼ë¦°\n* íƒ€ì´ë ˆë†€ ì„±ë¶„ì´ ë­ì•¼?"

        # [V11] ìµœì¢… ë‹µë³€ì„ ì±„íŒ… ê¸°ë¡ì— ì €ì¥
        st.session_state.messages.append({"role": "assistant", "content": reply_message})
        with st.chat_message("assistant"):
            st.markdown(reply_message)
            
        # [V11] st.rerun()ì„ ì‚¬ìš©í•˜ì§€ ì•Šì•„ ë‹µë³€ì´ ìœ ì§€ë©ë‹ˆë‹¤.