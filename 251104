import streamlit as st
import pandas as pd
import re

# 1. ë°ì´í„° ë¡œë“œ (í˜ì´ì§€ê°€ ë¡œë“œë  ë•Œ í•œ ë²ˆë§Œ ì‹¤í–‰ë¨)
@st.cache_data
def load_data():
    """druglist.csv íŒŒì¼ì„ ë¡œë“œí•˜ê³  ìºì‹œì— ì €ì¥í•©ë‹ˆë‹¤."""
    file_path = r'druglist.csv'
    try:
        # [ìˆ˜ì •ë¨] dtype=strì„ ì¶”ê°€í•˜ì—¬ DtypeWarningì„ ë°©ì§€í•©ë‹ˆë‹¤.
        df = pd.read_csv(file_path, encoding='utf-8', dtype=str)
        df['ìƒì„¸ì •ë³´'] = df['ìƒì„¸ì •ë³´'].fillna('ìƒí˜¸ì‘ìš© ì •ë³´ ì—†ìŒ')
        print("âœ… (Streamlit) ì•½ë¬¼ ìƒí˜¸ì‘ìš© ë°ì´í„° ë¡œë“œ ì„±ê³µ!")
        return df
    except FileNotFoundError:
        st.error(f"âŒ '{file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. .py íŒŒì¼ê³¼ ê°™ì€ í´ë”ì— ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None
    except UnicodeDecodeError:
        st.error(f"âŒ '{file_path}' íŒŒì¼ ì¸ì½”ë”©ì´ 'utf-8'ì´ ì•„ë‹Œ ê²ƒ ê°™ìŠµë‹ˆë‹¤. (íŒŒì¼ ì¸ì½”ë”©ì„ 'utf-8'ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”)")
        return None
    except Exception as e:
        st.error(f"âŒ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# ë°ì´í„° ë¡œë“œ ì‹¤í–‰
df = load_data()

# 2. ì•½ë¬¼ ê²€ìƒ‰ ë° ìƒí˜¸ì‘ìš© í•¨ìˆ˜ë“¤
def find_drug_info(df, query):
    """(ìˆ˜ì •) ì‚¬ìš©ì ì¿¼ë¦¬ë¡œë¶€í„° ì•½ë¬¼ ê´€ë ¨ ì •ë³´ë¥¼ ìœ ì—°í•˜ê²Œ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    
    # ì¿¼ë¦¬ ì „ì²˜ë¦¬: ê´„í˜¸ ë° íŠ¹ì • ì œí˜• ë‹¨ì–´ë§Œ ì œê±°
    cleaned_query = re.sub(r'\(.*?\)|\[.*?\]|ì£¼ì‚¬ì œ|ì •ì œ|ìº¡ìŠ|ì‹œëŸ½', '', query).strip().lower()
    
    if not cleaned_query:
        return pd.DataFrame(), None 
    
    try:
        search_pattern = re.escape(cleaned_query)
        
        search_results = df[
            df['ì œí’ˆëª…A'].str.contains(search_pattern, na=False) |
            df['ì„±ë¶„ëª…A'].str.contains(search_pattern, na=False) |
            df['ì œí’ˆëª…B'].str.contains(search_pattern, na=False) |
            df['ì„±ë¶„ëª…B'].str.contains(search_pattern, na=False)
        ]

        if search_results.empty:
            return None # [ìˆ˜ì •ë¨] find_drug_infoì˜ ë°˜í™˜ê°’ì„ ì¼ê´€ë˜ê²Œ Noneìœ¼ë¡œ ë³€ê²½

        # ê²€ìƒ‰ëœ ì•½ë¬¼ì˜ ëª¨ë“  ì´ë¦„/ì„±ë¶„ ì§‘í•©ì„ ë°˜í™˜
        drugs_set = set(search_results['ì œí’ˆëª…A']).union(set(search_results['ì„±ë¶„ëª…A'])).union(set(search_results['ì œí’ˆëª…B'])).union(set(search_results['ì„±ë¶„ëª…B']))
        drugs_set.discard('nan') # 'nan' ë¬¸ìì—´ ì œê±°
        drugs_set.add(cleaned_query) # ì›ë³¸ ì¿¼ë¦¬ë„ ì¶”ê°€
        
        return drugs_set

    except Exception as e:
        print(f"DEBUG: find_drug_infoì—ì„œ ì˜¤ë¥˜ ë°œìƒ - {e}")
        return None
    

def check_drug_interaction_flexible(df, drug_A_query, drug_B_query):
    """ [ìˆ˜ì •ë¨] ë¶€ë¶„ ê²€ìƒ‰ì–´ë¥¼ ì‚¬ìš©í•´ ìƒí˜¸ì‘ìš©ì„ ì§ì ‘ ê²€ìƒ‰í•˜ëŠ” ë¡œì§ """
    
    # 1. ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë¶€ë¶„ ê²€ìƒ‰ì–´ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤. (ìˆ«ì, í•œê¸€ ë“± ëª¨ë‘ í¬í•¨)
    pattern_A = re.escape(drug_A_query)
    pattern_B = re.escape(drug_B_query)

    # 2. ì•½ë¬¼ Aì™€ Bê°€ í¬í•¨ëœ ëª¨ë“  ì»¬ëŸ¼ì„ ì •ì˜í•©ë‹ˆë‹¤.
    cols_A = (df['ì œí’ˆëª…A'].str.contains(pattern_A, na=False, case=False) | df['ì„±ë¶„ëª…A'].str.contains(pattern_A, na=False, case=False))
    cols_B = (df['ì œí’ˆëª…B'].str.contains(pattern_B, na=False, case=False) | df['ì„±ë¶„ëª…B'].str.contains(pattern_B, na=False, case=False))

    # 3. ì•½ë¬¼ Bì™€ Aê°€ í¬í•¨ëœ ëª¨ë“  ì»¬ëŸ¼ì„ ì •ì˜í•©ë‹ˆë‹¤. (ìˆœì„œ ë°˜ëŒ€)
    cols_C = (df['ì œí’ˆëª…A'].str.contains(pattern_B, na=False, case=False) | df['ì„±ë¶„ëª…A'].str.contains(pattern_B, na=False, case=False))
    cols_D = (df['ì œí’ˆëª…B'].str.contains(pattern_A, na=False, case=False) | df['ì„±ë¶„ëª…B'].str.contains(pattern_A, na=False, case=False))

    # 4. (A & B) ë˜ëŠ” (B & A) ì¡°í•©ì— í•´ë‹¹í•˜ëŠ” ëª¨ë“  ìƒí˜¸ì‘ìš©ì„ í•œ ë²ˆì— ì°¾ìŠµë‹ˆë‹¤.
    interactions = df[(cols_A & cols_B) | (cols_C & cols_D)]

    if interactions.empty:
        return "ì•ˆì „", f"'{drug_A_query}'ì™€ '{drug_B_query}' ê°„ì˜ ìƒí˜¸ì‘ìš© ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."

    interactions = interactions.drop_duplicates(subset=['ìƒì„¸ì •ë³´'])


    # 5. ìœ„í—˜ë„ íŒë‹¨ ë¡œì§ (ê¸°ì¡´ê³¼ ë™ì¼)
    dangerous_keywords = ["ê¸ˆê¸°", "íˆ¬ì—¬ ê¸ˆì§€", "ë…ì„± ì¦ê°€", "ì¹˜ëª…ì ì¸", "ì‹¬ê°í•œ", "ìœ ì‚° ì‚°ì„±ì¦", "ê³ ì¹¼ë¥¨í˜ˆì¦", "ì‹¬ì‹¤ì„± ë¶€ì •ë§¥", "ìœ„í—˜ì„± ì¦ê°€", "ìœ„í—˜ ì¦ê°€", "ì‹¬ì¥ ë¶€ì •ë§¥", "QTê°„ê²© ì—°ì¥ ìœ„í—˜ ì¦ê°€", "QTì—°ì¥", "ì‹¬ë¶€ì •ë§¥", "ì¤‘ëŒ€í•œ", "ì‹¬ì¥ ëª¨ë‹ˆí„°ë§", "ë³‘ìš©ê¸ˆê¸°", "Torsade de pointes ìœ„í—˜ ì¦ê°€", "ìœ„í—˜ì´ ì¦ê°€í•¨", "ì•½ë¬¼ì´ìƒë°˜ì‘ ë°œìƒ ìœ„í—˜", "ë…ì„±", "í—ˆí˜ˆ", "í˜ˆê´€ê²½ë ¨", ]
    caution_keywords = ["ì¹˜ë£Œ íš¨ê³¼ê°€ ì œí•œì ", "ì¤‘ì¦ì˜ ìœ„ì¥ê´€ê³„ ì´ìƒë°˜ì‘", "Alfuzosin í˜ˆì¤‘ë†ë„ ì¦ê°€", "ì–‘ìª½ ì•½ë¬¼ ëª¨ë‘ í˜ˆì¥ë†ë„ ìƒìŠ¹ ê°€ëŠ¥", "Amiodarone í˜ˆì¤‘ë†ë„ ì¦ê°€", "í˜ˆì¤‘ë†ë„ ì¦ê°€", "íš¡ë¬¸ê·¼ìœµí•´ì™€ ê°™ì€ ì¤‘ì¦ì˜ ê·¼ìœ¡ì´ìƒ ë³´ê³ ",  "í˜ˆì¥ ë†ë„ ì¦ê°€", "Finerenone í˜ˆì¤‘ë†ë„ì˜ í˜„ì €í•œ ì¦ê°€ê°€ ì˜ˆìƒë¨"]

    risk_level = "ì•ˆì „" # ê¸°ë³¸ê°’
    reasons = []
    processed_details = set() 

    for detail in interactions['ìƒì„¸ì •ë³´'].unique():
        if detail in processed_details: continue
        detail_str = str(detail)
        processed_details.add(detail)
        
        found_danger = False
        for keyword in dangerous_keywords:
            if keyword in detail_str:
                risk_level = "ìœ„í—˜" 
                reasons.append(f"ğŸš¨ **ìœ„í—˜**: {detail_str}")
                found_danger = True
                break 
        
        if not found_danger:
            for keyword in caution_keywords:
                if keyword in detail_str:
                    if risk_level != "ìœ„í—˜": risk_level = "ì£¼ì˜"
                    reasons.append(f"âš ï¸ **ì£¼ì˜**: {detail_str}")
                    break 
    
    if not reasons:
        risk_level = "ì •ë³´ í™•ì¸"
        reasons.append("â„¹ï¸ ìƒí˜¸ì‘ìš© ì •ë³´ê°€ ìˆìœ¼ë‚˜, ì§€ì •ëœ ìœ„í—˜/ì£¼ì˜ í‚¤ì›Œë“œëŠ” ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì„¸ìš”.")
        for detail in interactions['ìƒì„¸ì •ë³´'].unique():
             if str(detail) not in processed_details:
                 reasons.append(f"â„¹ï¸ **ì •ë³´**: {str(detail)}")
            
    return risk_level, "\n\n".join(reasons)

# 3. Streamlit ì›¹ì‚¬ì´íŠ¸ UI ì½”ë“œ (ê¸°ì¡´ê³¼ ë™ì¼)
st.title("ğŸ’Š ì•½ë¬¼ ìƒí˜¸ì‘ìš© ì±—ë´‡")
st.caption("ìº¡ìŠ¤í†¤ í”„ë¡œì íŠ¸: ì•½ë¬¼ ìƒí˜¸ì‘ìš© ì •ë³´ ê²€ìƒ‰ ì±—ë´‡")

if "messages" not in st.session_state:
    st.session_state.messages = []

if not st.session_state.messages:
    st.session_state.messages.append(
        {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ì•½ë¬¼ ìƒí˜¸ì‘ìš© ì±—ë´‡ì…ë‹ˆë‹¤.\n\n[ì§ˆë¬¸ ì˜ˆì‹œ]\n1. íƒ€ì´ë ˆë†€ ì„±ë¶„ì´ ë­ì•¼?\n2. íƒ€ì´ë ˆë†€ê³¼ ì•„ìŠ¤í”¼ë¦°ì„ ê°™ì´ ë³µìš©í•´ë„ ë¼?"}
    )

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if df is None:
    st.error("ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ë¡œ ì±—ë´‡ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
else:
    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”... (ì˜ˆ: íƒ€ì´ë ˆë†€ê³¼ ì•„ìŠ¤í”¼ë¦°)"):
        
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        reply_message = ""
        
        # ì„±ë¶„ ì§ˆë¬¸
        match_component = re.match(r'(.+?)\s*ì„±ë¶„[ì´]?[ ]?(ë­ì•¼|ì•Œë ¤ì¤˜)\??', prompt.strip())
        if match_component:
            drug_name = match_component.group(1).strip('() ')
            if drug_name:
                # [ìˆ˜ì •] find_drug_info ë°˜í™˜ê°’ ë³€ê²½ë¨
                drugs_set = find_drug_info(df, drug_name)
                if drugs_set is not None:
                    components = {str(d) for d in drugs_set if pd.notna(d) and len(str(d)) > 3 and str(d) != 'nan'}
                    if components:
                        reply_message = f"âœ… '{drug_name}'ì˜ ê´€ë ¨ ì„±ë¶„ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n\n* {', '.join(components)}"
                    else:
                        reply_message = f"â„¹ï¸ '{drug_name}'ì„(ë¥¼) ì°¾ì•˜ìœ¼ë‚˜, ì—°ê´€ëœ ì„±ë¶„ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                else:
                    reply_message = f"â„¹ï¸ '{drug_name}'ì— ëŒ€í•œ ì •ë³´ë¥¼ ìƒí˜¸ì‘ìš© ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            else:
                reply_message = "âŒ ì–´ë–¤ ì•½ë¬¼ì˜ ì„±ë¶„ì„ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”? ì•½ë¬¼ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
        
        # ìƒí˜¸ì‘ìš© ì§ˆë¬¸
        match_interaction = re.match(r'(.+?)\s*(?:ì´ë‘|ë‘|ê³¼|ì™€|í•˜ê³ )\s+(.+?)(?:ë¥¼|ì„)?\s+(?:ê°™ì´|í•¨ê»˜)\s+(?:ë³µìš©í•´ë„|ë¨¹ì–´ë„)\s+(?:ë¼|ë˜ë‚˜|ë ê¹Œ|ë˜ë‚˜ìš”)\??', prompt.strip())
        
        if not match_interaction:
             match_interaction_simple = re.match(r'^\s*([^\s]+)\s+([^\s]+)\s*$', prompt.strip())
             if match_interaction_simple:
                 match_interaction = match_interaction_simple

        if match_interaction and not reply_message:
            drug_A_query = match_interaction.group(1).strip('() ')
            drug_B_query = match_interaction.group(2).strip('() ')
            
            if drug_A_query and drug_B_query:
                with st.spinner(f"ğŸ”„ '{drug_A_query}'ì™€ '{drug_B_query}' ìƒí˜¸ì‘ìš© ê²€ìƒ‰ ì¤‘..."):
                    risk, explanation = check_drug_interaction_flexible(df, drug_A_query, drug_B_query)
                
                if risk == "ì •ë³´ ì—†ìŒ":
                    reply_message = f"**ğŸ’Š ì•½ë¬¼ ìƒí˜¸ì‘ìš© ìœ„í—˜ë„: ì •ë³´ ì—†ìŒ**\n\n**ğŸ’¡ ìƒì„¸ ì •ë³´:**\n\n{explanation}ì— ëŒ€í•œ ì •ë³´ë¥¼ ìƒí˜¸ì‘ìš© ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì •ë³´ê°€ ë“±ë¡ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.)"
                else:
                    reply_message = f"**ğŸ’Š ì•½ë¬¼ ìƒí˜¸ì‘ìš© ìœ„í—˜ë„: {risk}**\n\n**ğŸ’¡ ìƒì„¸ ì •ë³´:**\n\n{explanation}"
            else:
                reply_message = "âŒ ë‘ ì•½ë¬¼ ì´ë¦„ì„ ì •í™•íˆ ì…ë ¥í•´ì£¼ì„¸ìš”. ì˜ˆ: (A)ì•½ë¬¼ê³¼ (B)ì•½ë¬¼ì„ ê°™ì´ ë³µìš©í•´ë„ ë¼?"
        
        elif not match_component and not match_interaction:
            reply_message = "ğŸ¤” ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ í˜•ì‹ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n\n  **[ì§ˆë¬¸ ì˜ˆì‹œ]**\n  * íƒ€ì´ë ˆë†€ê³¼ ì•„ìŠ¤í”¼ë¦°\n  * íƒ€ì´ë ˆë†€ ì„±ë¶„ì´ ë­ì•¼?"

        st.session_state.messages.append({"role": "assistant", "content": reply_message})
        with st.chat_message("assistant"):
            st.markdown(reply_message)
