import streamlit as st
import pandas as pd
import re

# 1. ë°ì´í„° ë¡œë“œ (í˜ì´ì§€ê°€ ë¡œë“œë  ë•Œ í•œ ë²ˆë§Œ ì‹¤í–‰ë¨)
@st.cache_data
def load_data():
    """druglist.csv íŒŒì¼ì„ ë¡œë“œí•˜ê³  ìºì‹œì— ì €ì¥í•©ë‹ˆë‹¤."""
    file_path = r'druglist.csv'
    try:
        df = pd.read_csv(file_path, encoding='utf-8', dtype=str)
        df['ìƒì„¸ì •ë³´'] = df['ìƒì„¸ì •ë³´'].fillna('ìƒí˜¸ì‘ìš© ì •ë³´ ì—†ìŒ')
        
        # [ìˆ˜ì •ë¨] ê²€ìƒ‰ì„ ìœ„í•´ ë¯¸ë¦¬ ì†Œë¬¸ìí™” ë° ê³µë°±/ê´„í˜¸/íŠ¹ìˆ˜ë¬¸ì ì œê±°
        for col in ['ì œí’ˆëª…A', 'ì„±ë¶„ëª…A', 'ì œí’ˆëª…B', 'ì„±ë¶„ëª…B']:
            df[col] = df[col].astype(str).str.lower().str.replace(r'[\s\(\)\[\]_/-]', '', regex=True)
            
        print("âœ… (Streamlit) ì•½ë¬¼ ìƒí˜¸ì‘ìš© ë°ì´í„° ë¡œë“œ ì„±ê³µ!")
        return df
    except FileNotFoundError:
        st.error(f"âŒ '{file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. .py íŒŒì¼ê³¼ ê°™ì€ í´ë”ì— ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None
    except UnicodeDecodeError:
        st.error(f"âŒ '{file_path}' íŒŒì¼ ì¸ì½”ë”©ì´ 'utf-8'ì´ ì•„ë‹Œ ê²ƒ ê°™ìŠµë‹ˆë‹¤. (íŒŒì¼ ì¸ì½”ë”©ì„ 'utf-8'ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”)")
        return None
    except Exception as e:
        st.error(f"âŒ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# ë°ì´í„° ë¡œë“œ ì‹¤í–‰
df = load_data()

# 2. ì•½ë¬¼ ê²€ìƒ‰ ë° ìƒí˜¸ì‘ìš© í•¨ìˆ˜ë“¤
def find_drug_info(df, query):
    """(ìˆ˜ì •) ê´„í˜¸/ê³µë°±/íŠ¹ìˆ˜ë¬¸ìë¥¼ ë¬´ì‹œí•˜ê³  ìœ ì—°í•˜ê²Œ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    
    # [ìˆ˜ì •ë¨] 1ë²ˆê³¼ ë™ì¼í•œ ì²­ì†Œ ê·œì¹™ ì ìš©
    cleaned_query = re.sub(r'[\s\(\)\[\]_/-]|ì£¼ì‚¬ì œ|ì •ì œ|ìº¡ìŠ|ì‹œëŸ½', '', query).strip().lower()
    
    if len(cleaned_query) < 2: # 2ê¸€ì ë¯¸ë§Œ ê²€ìƒ‰ ë°©ì§€
        return set()
    
    try:
        search_pattern = re.escape(cleaned_query)
        
        # [ìˆ˜ì •ë¨] ë¯¸ë¦¬ ì²˜ë¦¬ëœ ì»¬ëŸ¼ì—ì„œ ê²€ìƒ‰
        search_results = df[
            df['ì œí’ˆëª…A'].str.contains(search_pattern, na=False) |
            df['ì„±ë¶„ëª…A'].str.contains(search_pattern, na=False) |
            df['ì œí’ˆëª…B'].str.contains(search_pattern, na=False) |
            df['ì„±ë¶„ëª…B'].str.contains(search_pattern, na=False)
        ]

        if search_results.empty:
            return set() # ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ

        # ê²€ìƒ‰ëœ ì•½ë¬¼ì˜ ëª¨ë“  ì´ë¦„/ì„±ë¶„ ì§‘í•©ì„ ë°˜í™˜
        drugs_set = set(search_results['ì œí’ˆëª…A']).union(set(search_results['ì„±ë¶„ëª…A'])).union(set(search_results['ì œí’ˆëª…B'])).union(set(search_results['ì„±ë¶„ëª…B']))
        drugs_set.discard('nan') # 'nan' ë¬¸ìì—´ ì œê±°
        
        return drugs_set

    except Exception as e:
        print(f"DEBUG: find_drug_infoì—ì„œ ì˜¤ë¥˜ ë°œìƒ - {e}")
        return set()
    

def check_drug_interaction_flexible(df, drug_A_query, drug_B_query):
    """ [ìˆ˜ì •ë¨] ê´„í˜¸/ê³µë°± ë¬´ì‹œ + ë¶€ë¶„ ê²€ìƒ‰ + ëª¨í˜¸ì„± ê°ì§€ ë¡œì§ """
    
    # 1. ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì¿¼ë¦¬ë¥¼ 'ìƒˆë¡œìš´ ì²­ì†Œ ê·œì¹™'ìœ¼ë¡œ ì²­ì†Œí•©ë‹ˆë‹¤.
    cleaned_A = re.sub(r'[\s\(\)\[\]_/-]|ì£¼ì‚¬ì œ|ì •ì œ|ìº¡ìŠ|ì‹œëŸ½', '', drug_A_query).strip().lower()
    cleaned_B = re.sub(r'[\s\(\)\[\]_/-]|ì£¼ì‚¬ì œ|ì •ì œ|ìº¡ìŠ|ì‹œëŸ½', '', drug_B_query).strip().lower()

    if len(cleaned_A) < 2 or len(cleaned_B) < 2:
        return "ì •ë³´ ì—†ìŒ", "ì•½ë¬¼ ì´ë¦„ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. (2ê¸€ì ì´ìƒ ì…ë ¥)"

    # 2. 'ì²­ì†Œëœ' DB ì»¬ëŸ¼ì—ì„œ Aì™€ Bë¥¼ ì§ì ‘ ì°¾ìŠµë‹ˆë‹¤.
    pattern_A = re.escape(cleaned_A)
    pattern_B = re.escape(cleaned_B)

    cols_A = (df['ì œí’ˆëª…A'].str.contains(pattern_A, na=False) | df['ì„±ë¶„ëª…A'].str.contains(pattern_A, na=False))
    cols_B = (df['ì œí’ˆëª…B'].str.contains(pattern_B, na=False) | df['ì„±ë¶„ëª…B'].str.contains(pattern_B, na=False))
    
    cols_C = (df['ì œí’ˆëª…A'].str.contains(pattern_B, na=False) | df['ì„±ë¶„ëª…A'].str.contains(pattern_B, na=False))
    cols_D = (df['ì œí’ˆëª…B'].str.contains(pattern_A, na=False) | df['ì„±ë¶„ëª…B'].str.contains(pattern_A, na=False))

    interactions = df[(cols_A & cols_B) | (cols_C & cols_D)]

    if interactions.empty:
        return "ì•ˆì „", f"'{drug_A_query}'ì™€ '{drug_B_query}' ê°„ì˜ ìƒí˜¸ì‘ìš© ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."

    interactions = interactions.drop_duplicates(subset=['ìƒì„¸ì •ë³´'])

    # 3. [í•µì‹¬] ì°¾ì€ ê²°ê³¼ì˜ ìƒì„¸ì •ë³´ê°€ ëª‡ ì¢…ë¥˜ì¸ì§€ í™•ì¸
    unique_interactions = interactions['ìƒì„¸ì •ë³´'].unique()

    # 4. ìƒì„¸ì •ë³´ê°€ 2ê°œ ì´ìƒì´ë©´ (ì˜ˆ: 25mgì™€ 50mg), ê²½ê³  ë©”ì‹œì§€ ë°˜í™˜
    if len(unique_interactions) > 1:
        risk_level = "ì •ë³´ í™•ì¸" 
        warning_msg = f"ğŸ” **ê²€ìƒ‰ ê²°ê³¼ê°€ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤.**\n\n'{drug_A_query}' ë˜ëŠ” '{drug_B_query}'ì— í•´ë‹¹í•˜ëŠ” ì œí’ˆ/ìš©ëŸ‰ì´ ì—¬ëŸ¬ ê°œ ìˆìŠµë‹ˆë‹¤. ì•½ë¬¼ ì´ë¦„ì„ ë” ì •í™•í•˜ê²Œ ì…ë ¥í•´ì£¼ì„¸ìš”.\n(ì˜ˆ: 'êµ¬ì£¼ì—¼ì‚°í˜ì¹˜ë”˜ì£¼ 50mg')"
        return risk_level, warning_msg

    # 5. ìƒì„¸ì •ë³´ê°€ 1ê°œì¼ ë•Œë§Œ, ìœ„í—˜ë„ í‚¤ì›Œë“œ ë¶„ì„
    dangerous_keywords = ["ì‚¬ë§", "í¥ë¶„", "ì •ì‹ ì°©ë€", "ê¸ˆê¸°", "íˆ¬ì—¬ ê¸ˆì§€", "ë…ì„± ì¦ê°€", "ì¹˜ëª…ì ì¸", "ì‹¬ê°í•œ", "ìœ ì‚° ì‚°ì„±ì¦", "ê³ ì¹¼ë¥¨í˜ˆì¦", "ì‹¬ì‹¤ì„± ë¶€ì •ë§¥", "ìœ„í—˜ì„± ì¦ê°€", "ìœ„í—˜ ì¦ê°€", "ì‹¬ì¥ ë¶€ì •ë§¥", "QTê°„ê²© ì—°ì¥ ìœ„í—˜ ì¦ê°€", "QTì—°ì¥", "ì‹¬ë¶€ì •ë§¥", "ì¤‘ëŒ€í•œ", "ì‹¬ì¥ ëª¨ë‹ˆí„°ë§", "ë³‘ìš©ê¸ˆê¸°", "Torsade de pointes ìœ„í—˜ ì¦ê°€", "ìœ„í—˜ì´ ì¦ê°€í•¨", "ì•½ë¬¼ì´ìƒë°˜ì‘ ë°œìƒ ìœ„í—˜", "ë…ì„±", "í—ˆí˜ˆ", "í˜ˆê´€ê²½ë ¨", ]
    caution_keywords = ["ì¹˜ë£Œ íš¨ê³¼ê°€ ì œí•œì ", "ì¤‘ì¦ì˜ ìœ„ì¥ê´€ê³„ ì´ìƒë°˜ì‘", "Alfuzosin í˜ˆì¤‘ë†ë„ ì¦ê°€", "ì–‘ìª½ ì•½ë¬¼ ëª¨ë‘ í˜ˆì¥ë†ë„ ìƒìŠ¹ ê°€ëŠ¥", "Amiodarone í˜ˆì¤‘ë†ë„ ì¦ê°€", "í˜ˆì¤‘ë†ë„ ì¦ê°€", "íš¡ë¬¸ê·¼ìœµí•´ì™€ ê°™ì€ ì¤‘ì¦ì˜ ê·¼ìœ¡ì´ìƒ ë³´ê³ ",  "í˜ˆì¥ ë†ë„ ì¦ê°€", "Finerenone í˜ˆì¤‘ë†ë„ì˜ í˜„ì €í•œ ì¦ê°€ê°€ ì˜ˆìƒë¨"]

    risk_level = "ì•ˆì „" # ê¸°ë³¸ê°’
    reasons = []
    processed_details = set() 

    for detail in interactions['ìƒì„¸ì •ë³´'].unique():
        if detail in processed_details: continue
        detail_str = str(detail)
        processed_details.add(detail)
        
        found_danger = False
        for keyword in dangerous_keywords:
            if keyword in detail_str:
                risk_level = "ìœ„í—˜" 
                reasons.append(f"ğŸš¨ **ìœ„í—˜**: {detail_str}")
                found_danger = True
                break 
        
        if not found_danger:
            for keyword in caution_keywords:
                if keyword in detail_str:
                    if risk_level != "ìœ„í—˜": risk_level = "ì£¼ì˜"
                    reasons.append(f"âš ï¸ **ì£¼ì˜**: {detail_str}")
                    break 
    
    if not reasons:
        risk_level = "ì •ë³´ í™•ì¸"
        reasons.append("â„¹ï¸ ìƒí˜¸ì‘ìš© ì •ë³´ê°€ ìˆìœ¼ë‚˜, ì§€ì •ëœ ìœ„í—˜/ì£¼ì˜ í‚¤ì›Œë“œëŠ” ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì„¸ìš”.")
        for detail in interactions['ìƒì„¸ì •ë³´'].unique():
             if str(detail) not in processed_details:
                 reasons.append(f"â„¹ï¸ **ì •ë³´**: {str(detail)}")
            
    return risk_level, "\n\n".join(reasons)

# 3. Streamlit ì›¹ì‚¬ì´íŠ¸ UI ì½”ë“œ (ê¸°ì¡´ê³¼ ë™ì¼)
st.title("ğŸ’Š ì•½ë¬¼ ìƒí˜¸ì‘ìš© ì±—ë´‡")
st.caption("ìº¡Sí†¤ í”„ë¡œì íŠ¸: ì•½ë¬¼ ìƒí˜¸ì‘ìš© ì •ë³´ ê²€ìƒ‰ ì±—ë´‡")

if "messages" not in st.session_state:
    st.session_state.messages = []

if not st.session_state.messages:
    st.session_state.messages.append(
        {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ì•½ë¬¼ ìƒí˜¸ì‘ìš© ì±—ë´‡ì…ë‹ˆë‹¤.\n\n[ì§ˆë¬¸ ì˜ˆì‹œ]\n1. íƒ€ì´ë ˆë†€ ì„±ë¶„ì´ ë­ì•¼?\n2. íƒ€ì´ë ˆë†€ê³¼ ì•„ìŠ¤í”¼ë¦°ì„ ê°™ì´ ë³µìš©í•´ë„ ë¼?"}
    )

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if df is None:
    st.error("ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ë¡œ ì±—ë´‡ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
else:
    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”... (ì˜ˆ: íƒ€ì´ë ˆë†€ê³¼ ì•„ìŠ¤í”¼ë¦°)"):
        
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        reply_message = ""
        
        # ì„±ë¶„ ì§ˆë¬¸
        match_component = re.match(r'(.+?)\s*ì„±ë¶„[ì´]?[ ]?(ë­ì•¼|ì•Œë ¤ì¤˜)\??', prompt.strip())
        if match_component:
            drug_name = match_component.group(1).strip('() ')
            if drug_name:
                drugs_set = find_drug_info(df, drug_name)
                if drugs_set:
                    components = {str(d) for d in drugs_set if pd.notna(d) and len(str(d)) > 3 and str(d) != 'nan'}
                    if components:
                        reply_message = f"âœ… '{drug_name}'ì˜ ê´€ë ¨ ì„±ë¶„ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n\n* {', '.join(components)}"
                    else:
                        reply_message = f"â„¹ï¸ '{drug_name}'ì„(ë¥¼) ì°¾ì•˜ìœ¼ë‚˜, ì—°ê´€ëœ ì„±ë¶„ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                else:
                    reply_message = f"â„¹ï¸ '{drug_name}'ì— ëŒ€í•œ ì •ë³´ë¥¼ ìƒí˜¸ì‘ìš© ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            else:
                reply_message = "âŒ ì–´ë–¤ ì•½ë¬¼ì˜ ì„±ë¶„ì„ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”? ì•½ë¬¼ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
        
        # ìƒí˜¸ì‘ìš© ì§ˆë¬¸
        match_interaction = re.match(r'(.+?)\s*(?:ì´ë‘|ë‘|ê³¼|ì™€|í•˜ê³ )\s+(.+?)(?:ë¥¼|ì„)?\s+(?:ê°™ì´|í•¨ê»˜)\s+(?:ë³µìš©í•´ë„|ë¨¹ì–´ë„)\s+(?:ë¼|ë˜ë‚˜|ë ê¹Œ|ë˜ë‚˜ìš”)\??', prompt.strip())
        
        if not match_interaction:
             match_interaction_simple = re.match(r'^\s*([^\s]+)\s+([^\s]+)\s*$', prompt.strip())
             if match_interaction_simple:
                 match_interaction = match_interaction_simple

        if match_interaction and not reply_message:
            drug_A_query = match_interaction.group(1).strip('() ')
            drug_B_query = match_interaction.group(2).strip('() ')
            
            if drug_A_query and drug_B_query:
                with st.spinner(f"ğŸ”„ '{drug_A_query}'ì™€ '{drug_B_query}' ìƒí˜¸ì‘ìš© ê²€ìƒ‰ ì¤‘..."):
                    risk, explanation = check_drug_interaction_flexible(df, drug_A_query, drug_B_query)
                
                if risk == "ì •ë³´ ì—†ìŒ":
                    reply_message = f"**ğŸ’Š ì•½ë¬¼ ìƒí˜¸ì‘ìš© ìœ„í—˜ë„: ì •ë³´ ì—†ìŒ**\n\n**ğŸ’¡ ìƒì„¸ ì •ë³´:**\n\n{explanation}"
                else:
                    reply_message = f"**ğŸ’Š ì•½ë¬¼ ìƒí˜¸ì‘ìš© ìœ„í—˜ë„: {risk}**\n\n**ğŸ’¡ ìƒì„¸ ì •ë³´:**\n\n{explanation}"
            else:
                reply_message = "âŒ ë‘ ì•½ë¬¼ ì´ë¦„ì„ ì •í™•íˆ ì…ë ¥í•´ì£¼ì„¸ìš”. ì˜ˆ: (A)ì•½ë¬¼ê³¼ (B)ì•½ë¬¼ì„ ê°™ì´ ë³µìš©í•´ë„ ë¼?"
        
        elif not match_component and not match_interaction:
            reply_message = "ğŸ¤” ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ í˜•ì‹ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n\n  **[ì§ˆë¬¸ ì˜ˆì‹œ]**\n  * íƒ€ì´ë ˆë†€ê³¼ ì•„ìŠ¤í”¼ë¦°\n  * íƒ€ì´ë ˆë†€ ì„±ë¶„ì´ ë­ì•¼?"

        st.session_state.messages.append({"role": "assistant", "content": reply_message})
        with st.chat_message("assistant"):
            st.markdown(reply_message)
